{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'cam_data.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    X_train = pickle_data['train_data']\n",
    "    y_train = pickle_data['train_label']\n",
    "    X_valid = pickle_data['valid_data']\n",
    "    y_valid = pickle_data['valid_label']\n",
    "    X_test = pickle_data['test_data']\n",
    "    y_test = pickle_data['test_label']\n",
    "    del pickle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data features: (192, 18, 80, 1)\n",
      "size of training data labels: (192,)\n",
      "size of validation data features: (48, 18, 80, 1)\n",
      "size of validation data labels: (48,)\n",
      "size of test data features: (60, 18, 80, 1)\n",
      "size of test data labels: (60,)\n"
     ]
    }
   ],
   "source": [
    "#squash to 0-1 or -0.5 - 0.5\n",
    "#going with -0.5/0.5 for now for 0 mean\n",
    "def squash(data):\n",
    "    data = data/255 - 0.5\n",
    "    return data\n",
    "\n",
    "X_train = squash(X_train.astype('float32'))\n",
    "X_valid = squash(X_valid.astype('float32'))\n",
    "X_test = squash(X_test.astype('float32'))\n",
    "\n",
    "print(\"size of training data features:\", X_train.shape)\n",
    "print(\"size of training data labels:\", y_train.shape)\n",
    "print(\"size of validation data features:\", X_valid.shape)\n",
    "print(\"size of validation data labels:\", y_valid.shape)\n",
    "print(\"size of test data features:\", X_test.shape)\n",
    "print(\"size of test data labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 80, 1) input shape\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 1\n",
    "nb_epoch = 10\n",
    "batch_size = 32\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape, 'input shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing models. importing...\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_4 (Convolution2D)  (None, 16, 78, 16)    160         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16, 78, 16)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 14, 76, 8)     1160        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 14, 76, 8)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 12, 74, 4)     292         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 12, 74, 4)     0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 6, 37, 4)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 6, 37, 4)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 888)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 16)            14224       flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 16)            0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 16)            272         activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 16)            0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 16)            272         activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 16)            0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             17          dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 16,397\n",
      "Trainable params: 16,397\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 0s - loss: 0.0122 - acc: 0.1667 - val_loss: 0.0077 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s - loss: 0.0068 - acc: 0.1667 - val_loss: 0.0060 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s - loss: 0.0057 - acc: 0.1667 - val_loss: 0.0060 - val_acc: 0.2500\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s - loss: 0.0060 - acc: 0.1667 - val_loss: 0.0059 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s - loss: 0.0053 - acc: 0.1667 - val_loss: 0.0059 - val_acc: 0.2500\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s - loss: 0.0054 - acc: 0.1667 - val_loss: 0.0057 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s - loss: 0.0049 - acc: 0.1667 - val_loss: 0.0055 - val_acc: 0.2500\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s - loss: 0.0049 - acc: 0.1667 - val_loss: 0.0054 - val_acc: 0.2500\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s - loss: 0.0048 - acc: 0.1667 - val_loss: 0.0049 - val_acc: 0.2500\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s - loss: 0.0044 - acc: 0.1667 - val_loss: 0.0046 - val_acc: 0.2500\n",
      "Test score: 0.00466922049721\n",
      "Test accuracy: 0.166666668653\n",
      "The file already exists, overwrite? Y/n \n",
      "\n",
      "y\n",
      "overwrite complete\n"
     ]
    }
   ],
   "source": [
    "# load model if already compiled\n",
    "\n",
    "try:\n",
    "    with open('model.json', 'r') as J:\n",
    "        model = model_from_json(json.load(J))\n",
    "\n",
    "    print(\"found existing models. importing...\\n\")\n",
    "    model.compile('adam', 'mse6')\n",
    "    model.load_weights('model.h5')\n",
    "    print(\"model import success...\\n\")\n",
    "except:\n",
    "    #model parameters\n",
    "    nb_first_filter = 16\n",
    "    nb_second_filter = 8\n",
    "    nb_third_filter = 4\n",
    "    nb_fourth_filter = 2\n",
    "    pool_size = (2,2)\n",
    "    kernel_size = (3,3)\n",
    "    \n",
    "    #initiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(\n",
    "            nb_first_filter, kernel_size[0], kernel_size[1], border_mode='valid', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Convolution2D(\n",
    "            nb_second_filter, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(\n",
    "            nb_third_filter, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_valid, y_valid))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "if 'model.json' in os.listdir():\n",
    "    print(\"The file already exists, overwrite? Y/n \\n\")\n",
    "    user_input = input()\n",
    "    \n",
    "    if user_input == 'y' or 'Y':\n",
    "        json_string = model.to_json()\n",
    "        \n",
    "        with open('model.json', 'w') as outfile:\n",
    "            json.dump(json_string, outfile)\n",
    "            model.save('./model.h5')\n",
    "            print(\"overwrite complete\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Aborting..\")\n",
    "else:\n",
    "    json_string = model.to_json()\n",
    "    \n",
    "    with open('model.json', 'w') as outfile:\n",
    "        json.dump(json_string, outfile)\n",
    "        model.save('./model.h5')\n",
    "        print(\"Save complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
